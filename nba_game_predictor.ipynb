{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78d904cb",
   "metadata": {},
   "source": [
    "Checking The Dataset Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a697d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.linear_model import RidgeClassifier \n",
    "from sklearn.feature_selection import SequentialFeatureSelector \n",
    "from sklearn.model_selection import TimeSeriesSplit  \n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "import plotly.express as px  \n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bee8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and tidying up dataframe \n",
    "nba_df = pd.read_csv(\"nba_games.csv\", index_col=0) \n",
    "nba_df = nba_df.sort_values(by=\"date\") #sorting by date \n",
    "nba_df= nba_df.reset_index(drop=True)  # prevents old index from becoming a column \n",
    "nba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ef0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to define the target variable \n",
    "def add_targetvar(team): \n",
    "    team[\"target\"] = team[\"won\"].shift(-1) # Target var is the team's result in their next game; gets result by pulling the value of team[\"won\"] from the next row \n",
    "    return team \n",
    "\n",
    "nba_df = nba_df.groupby(\"team\", group_keys=False).apply(add_targetvar) \n",
    "nba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520e945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_df[nba_df[\"team\"] == \"TOR\"] #favourite team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all null values in target column with a 2 & converting target column into integers\n",
    "nba_df[\"target\"].fillna(2,inplace=True)  # 2 means null value\n",
    "nba_df[\"target\"] = nba_df[\"target\"].astype(int,errors=\"ignore\") # 0=loss & 1=win\n",
    "nba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a726e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking columns with null values \n",
    "nulls = nba_df.isnull().sum() \n",
    "nulls = nulls[nulls > 0] # Finding columns with at least 1 null value; discovered 6 columns with null values for each row \n",
    "nulls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4b345fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all columns with null values \n",
    "nba_df = nba_df.drop([\"mp.1\",\"mp_opp.1\", \"index_opp\", \"+/-\", \"mp_max\", \"mp_max.1\", \"+/-_opp\", \"mp_max_opp\", \"mp_max_opp.1\"], axis=1) # down to 147 columns  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f82dd7",
   "metadata": {},
   "source": [
    "Data Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c1ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(nba_df, y=\"fg%\", x=\"target\",  box=True, points=\"all\",\n",
    "          hover_data=nba_df.columns)\n",
    "fig.show() # Higher fg% equates to higher chance of winning next game "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcefd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(nba_df, y=\"3p%\", x=\"target\",  box=True, points=\"all\",\n",
    "          hover_data=nba_df.columns)\n",
    "fig.show() # Higher e point fg% equates to higher chance of winning next game "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e855407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(nba_df, y=\"orb\", x=\"target\",  box=True, points=\"all\",\n",
    "          hover_data=nba_df.columns)\n",
    "fig.show() # Doesn't affect winning a lot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360bfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(nba_df, y=\"ts%\", x=\"target\",  box=True, points=\"all\",\n",
    "          hover_data=nba_df.columns)\n",
    "fig.show() #  Higher ts% does help with winning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aaf517",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(nba_df, y=\"pts_max_opp\", x=\"target\",  box=True, points=\"all\",\n",
    "          hover_data=nba_df.columns)\n",
    "fig.show() # doesn't have an impact on winning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce4a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(nba_df, y=\"3p_opp\", x=\"target\",  box=True, points=\"all\",\n",
    "          hover_data=nba_df.columns)\n",
    "fig.show() # Slightly helps with winning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(nba_df, y=\"blk_opp\", x=\"target\",  box=True, points=\"all\",\n",
    "          hover_data=nba_df.columns)\n",
    "fig.show() # Helps with winning; less blocks from opponents -> more chance of winning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bdc869",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(nba_df, y=\"fg_opp\", x=\"target\",  box=True, points=\"all\",\n",
    "          hover_data=nba_df.columns)\n",
    "fig.show() # Slighlty increases chance of winning; lower fg -> higher chance of winning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756a9315",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(nba_df, y=\"tov_opp\", x=\"target\",  box=True, points=\"all\",\n",
    "          hover_data=nba_df.columns)\n",
    "fig.show() # Does help with winning; more tov from opp -> more opportunities to score -> higher chance of winning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30792193",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(nba_df, y=\"tov%_max\", x=\"target\",  box=True, points=\"all\",\n",
    "          hover_data=nba_df.columns)\n",
    "fig.show() # Doesn't really impact winning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43bdc7",
   "metadata": {},
   "source": [
    "Getting The Best Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a704ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining classifier, cross-validator, and feature selector\n",
    "ridge = RidgeClassifier(alpha=1) \n",
    "tscv = TimeSeriesSplit(n_splits=3) #Splits dataset based on time \n",
    "sfs = SequentialFeatureSelector(ridge, n_features_to_select=30, direction=\"forward\",cv=tscv, n_jobs=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f03e8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_columns = [\"season\", \"date\", \"won\", \"target\", \"team\", \"team_opp\"]  # List of all categorical columns \n",
    "wanted_columns = nba_df.columns[~nba_df.columns.isin(unwanted_columns)] # Excluding categorical columns \n",
    "\n",
    "scaler = MinMaxScaler() \n",
    "nba_df[wanted_columns] = scaler.fit_transform(nba_df[wanted_columns]) \n",
    "nba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ba9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the feature selector to input and target variables\n",
    "sfs.fit(nba_df[wanted_columns], nba_df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8f44d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the best predictors \n",
    "best_columns = list(wanted_columns[sfs.get_support()])  \n",
    "best_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eeb08b",
   "metadata": {},
   "source": [
    "Testing the Initial Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f964bad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data, model,predictors,start=2, step=1): \n",
    "\n",
    "    all_preds = [] # List for predictions for all seasons \n",
    "\n",
    "    seasons = sorted(data[\"season\"].unique()) # Sorted list of all seasons in the dataframe  \n",
    "\n",
    "    for i in range(start, len(seasons), step): \n",
    "\n",
    "        season = seasons[i] \n",
    "        train = data[data[\"season\"] < season] # Train set should include data from previous seasons \n",
    "        test = data[data[\"season\"] == season] \n",
    "\n",
    "        model.fit(train[predictors], train[\"target\"]) \n",
    "\n",
    "        preds = model.predict(test[predictors]) #Will be a numpy arrary; hard to work with; convert to dataframe \n",
    "        preds = pd.Series(preds, index=test.index)  # Convert numpy arrary to pandas Series \n",
    "\n",
    "        combined_preds = pd.concat([test[\"target\"], preds], axis=1) # Combining target columns from test data and the predictions for side-by-side comparison \n",
    "        combined_preds.columns = [\"Actual\", \"Predicted\"] # Renaming columns \n",
    "\n",
    "        all_preds.append(combined_preds) # Adding predictions for all seasons to an empty list\n",
    "        \n",
    "    return pd.concat(all_preds) # Combining all predictions from the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa18136",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_predictions = test(nba_df, ridge, best_columns) \n",
    "initial_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09bd03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = accuracy_score(initial_predictions[\"Actual\"] , initial_predictions[\"Predicted\"]) # Changing it to !=2 lowers accuracy; need to find out why this happens\n",
    "test_accuracy # We need to determine the baseline accuracy to beat; one baseline could be chance of winning home games; if my model is more accurate than someone blindly guessing that all \n",
    "# teams will win their home games, my model has produced some sort of useful prediction; next steps: beating Vegas odds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7453114",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_df.groupby([\"home\"]).apply(lambda x: x[x[\"won\"] == 1].shape[0] / x.shape[0]) # 57.2% chance of winning home games; have to beat this accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3cfaa2",
   "metadata": {},
   "source": [
    "Generating Rolling Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "406e0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling averages allow us to determine if the team is going to win or not based on multiple previous games rather than relying on a single previous game  \n",
    "\n",
    "# Create a df for rolling averages \n",
    "# Create a function that calculates rolling averages and apply it to the df created in step 1  \n",
    "# Remove null values \n",
    "# Rename the rolling avg columns to avoid overlap with the pre-existing df(nba_df) \n",
    "# Concatenate the dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9345980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_columns = [col for col in wanted_columns if col != \"home\"] # Excluding home column as I don't want to calculate the rolling average for an encoded column \n",
    "nba_df_rolling = nba_df[list(wanted_columns) + [\"won\", \"team\", \"season\"]] # Copying wanted numerical columns and the categorical columns to a new dataframe \n",
    "\n",
    "def find_team_averages(team):\n",
    "    rolling = team[wanted_columns].rolling(10).mean() # Applying rolling averages of previous 10 games for numerical columns \n",
    "    rolling[\"won\"] = team[\"won\"]  # Copying the categorical won column onto the rolling dataframe; same step for every other categorical column \n",
    "    rolling[\"team\"] = team[\"team\"]\n",
    "    rolling[\"season\"] = team[\"season\"]   \n",
    "    return rolling\n",
    "\n",
    "nba_df_rolling = nba_df_rolling.groupby([\"team\", \"season\"], group_keys=False).apply(find_team_averages) #Applying the rolling averages function to the dataframe\n",
    "nba_df_rolling # Grouping by team and season is needed in order to calculate the rolling averages for each specific team and season; otherwise, the rolling averages would be calculated based on the random order of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebd45d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_cols_list = list(nba_df_rolling.columns) \n",
    "rolling_cols_list = [f\"{col}_10\" for col in rolling_cols_list] # Renaming rolling average columns \n",
    "rolling_cols_list \n",
    "nba_df_rolling.columns = rolling_cols_list \n",
    "nba_df = pd.concat([nba_df, nba_df_rolling], axis=1) # Joining the rolling averages dataframe with the original dataframe; axis=1 means columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de702610",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_df = nba_df.dropna() # Dropping null values; 2 rows dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25332b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6d3a50",
   "metadata": {},
   "source": [
    "Adding information regarding opponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afdb55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_col(team, col_name):\n",
    "    next_col = team[col_name].shift(-1)\n",
    "    return next_col # Shifts specific columns up by 1 to get the next game data \n",
    "\n",
    "def add_col(df, col_name): \n",
    "    return df.groupby(\"team_10\", group_keys=False).apply(lambda x: shift_col(x, col_name)) # Adding a new column that stores data regarding a team's next game \n",
    "\n",
    "nba_df[\"home_next\"] = add_col(nba_df, \"home\")\n",
    "nba_df[\"team_opp_next\"] = add_col(nba_df, \"team_opp\")\n",
    "nba_df[\"date_next\"] = add_col(nba_df, \"date\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6b1fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca2a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_df[\"team_10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0532856",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = nba_df.merge(nba_df[rolling_cols_list + [\"team_opp_next\", \"date_next\", \"team\"]], left_on=[\"team\", \"date_next\"], right_on=[\"team_opp_next\", \"date_next\"]) \n",
    "full_df\n",
    "\n",
    "# Creating a dataframe that contains the rolling averages of a team and the rolling averages of the opponent team for the next game; left_on and right_on indicate the direction of the columns\n",
    "# Number of rows also decreased because merge removes rows with null values; 108 rows were dropped because these rows contain data regarding the last game of the season; hence no next game data is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a945d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[[\"team_x\",\"team_opp_next_x\",\"team_y\", \"team_opp_next_y\", \"date\"]] #Left side is the team data and right side is the opponent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ac57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6cfc51",
   "metadata": {},
   "source": [
    "Training and Testing A More Accurate Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7606f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_columns =  list(full_df.columns[full_df.dtypes == \"object\"]) + unwanted_columns # Defining all categorical columns from the full_df \n",
    "unwanted_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e2fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = full_df.columns[~full_df.columns.isin(unwanted_columns)] # Excluding categorical columns \n",
    "sfs.fit(full_df[selected_columns], full_df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90122c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_columns = list(selected_columns[sfs.get_support()]) # Retrieving the best predictors  \n",
    "best_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9406516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test(full_df, ridge, best_columns) # Getting the predictions by calling the test function \n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6674efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = accuracy_score(predictions[\"Actual\"], predictions[\"Predicted\"]) # Getting the accuracy score \n",
    "test_accuracy # 63.2% accuracy; 8.5% increase from the last model and also beat the naive model as well ; still a long way to go "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cb85eb",
   "metadata": {},
   "source": [
    "How to Improve Model Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using other models(i.e XGBoost, Random Forest Classifier) \n",
    "# Optimizing hyperparameters of sfs; ie changing the number of features to select and the direction of the feature selection \n",
    "# Optimizing hyperparameters of the model; ie changing the alpha value of the RidgeClassifier \n",
    "# Changing ratio of rolling averages; previous 5 games, previous 15 games, etc \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcbb0b1",
   "metadata": {},
   "source": [
    "How to Get Predictions for Future Games "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb79c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get up to date data \n",
    "# Fill in the missing rows(games that have not happened yet) \n",
    "# Fit the sfs to target value of 2; indicates that game has not happened yet  \n",
    "# Get predictions for these games "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
